---
layout: tutorials
title: Automated Fiber Quantification
author: naomi
comments: true
date: 2016-09-20
---

## Objectives

After you complete this section, you should be able to:

1. Describe the AFQ pipeline
2. Identify the 20 fiber tracts generated by AFQ
3. Identify the 8 corpus callosum regions segmented
4. Run AFQ on the supercomputer
5. Segment the corpus callosum

## Tracts

Once preprocessing is completed using **dtiInit**, white matter pathways can be automatically identified using the software package, Automated Fiber Quantification version 1.2 (https://github.com/yeatmanlab/AFQ). First, whole-brain tractography is estimated using a deterministic streamline tracking algorithm (STT). Individual fibers are assigned to a fiber tract if they pass through two waypoint ROIs that were used to define the trajectory of the pathway. ROIs are automatically placed in equivalent anatomical locations across each participant by registering a template to each participant. Finally, identified fiber tracts are validated by comparing each tract to a fiber tract probability map. Fibers within the identified fiber tract of low probability are discarded, because they do not conform to the shape of the fiber tract as defined by the fiber probability map.

### Fiber Tracts

<img class="img-responsive" alt="" src="images/afq.jpg">

### Corpus Callosum

<img class="img-responsive" alt="" src="images/cc.jpg">

The 8 regions of the corpus callosum are as follows:

1. Orbital frontal
2. Superior frontal
3. Anterior frontal
4. Motor
5. Superior Parietal
6. Posterior Parietal
7. Occipital
8. Temporal

## Automated Fiber Quantification (AFQ)

After you've preprocessed your diffusion weighted data using **dtiInit**, you are ready to run the AFQ pipeline. Let's create the output directories for these analyses:

{% highlight bash %}
mkdir -p ~/compute/analyses/EDSD/AFQ
mkdir -p ~/compute/analyses/EDSD/AFQ-CC
{% endhighlight %}

### Parameters

AFQ pipeline needs several MATLAB vectors in order to run. First, you will need to set the **path** to each participant's dt6.mat file under the variable **sub_dirs**, then you will need to set the group information (0 for the control group and 1 for study group) under the variable **sub_group**. In order to keep a record of the process, let's make this into a script. Create a script that will generate a variables, **sub_dirs** and **sub_group**, and save them as a .mat files:

{% highlight bash %}
vi ~/scripts/EDSD/afq_parameters.m
{% endhighlight %}

In the script, copy and paste your variable information:

{% highlight MATLAB %}
var = getenv('HOME');
sub_dirs = {[var,'/compute/images/EDSD/FRE_AD001/dti55trilin/'],...
[var,'/compute/images/EDSD/FRE_AD002/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_AD003/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_AD004/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_AD005/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_AD006/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_AD007/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_AD008/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_AD009/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_AD010/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC001/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC002/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC003/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC004/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC005/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC006/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC007/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC008/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC009/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC010/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC011/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC012/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC013/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC014/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC015/dti61trilin/'],...
[var,'/compute/images/EDSD/FRE_HC016/dti61trilin/']};
sub_group = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
save('~/compute/analyses/EDSD/AFQ/sub_dirs.mat','sub_dirs');
save('~/compute/analyses/EDSD/AFQ/sub_group.mat','sub_group');
quit
{% endhighlight %}

To run the script:

{% highlight bash %}
cd ~/scripts/EDSD/
module load matlab
matlab -nodisplay -nojvm -nosplash -r afq_parameters
module unload matlab
{% endhighlight %}

### Job Script

The job script simply submits the MATLAB function **afq_analysis**:

{% highlight bash %}
vi ~/scripts/EDSD/afq_job.sh
{% endhighlight %}

Copy and paste:

{% highlight bash %}
#!/bin/bash

#SBATCH --time=15:00:00   # walltime
#SBATCH --ntasks=1  # number of processor cores (i.e. tasks)
#SBATCH --nodes=1   # number of nodes
#SBATCH --mem-per-cpu=24576M   # memory per CPU core

# Compatibility variables for PBS. Delete if not needed.
export PBS_NODEFILE=`/fslapps/fslutils/generate_pbs_nodefile`
export PBS_JOBID=$SLURM_JOB_ID
export PBS_O_WORKDIR="$SLURM_SUBMIT_DIR"
export PBS_QUEUE=batch

# Set the max number of threads to use for programs using OpenMP. Should be <= ppn. Does nothing if the program doesn't use OpenMP.
export OMP_NUM_THREADS=$SLURM_CPUS_ON_NODE

# LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE
cd ~/scripts/EDSD/
module load matlab/r2013b
matlab -nodisplay -nojvm -nosplash -r afq_analysis
{% endhighlight %}

### MATLAB Script

Create your MATLAB script:

{% highlight bash %}
vi ~/scripts/EDSD/afq_analysis.m
{% endhighlight %}

**AFQ_run** is the main function to run the AFQ analysis pipeline.  When **AFQ_run** is used to analyze data all the proceeding analyses are organized into the **afq** data structure. You need to create a blank **afq** structure first using the **AFQ_Create** command and include the variables **sub_dirs** and **sub_group**. The **sub_dirs** variable should consist of a 1 x N cell array where N is the number of subjects in the study. Each cell should contain the full path to a subjects data directory where there dt6.mat file is (see above). The **sub_group** variable should consisit of a binary vector defining each subject's group. 0 for control and 1 for patient (see above). Since we've already created these variables above, we just have to load them in MATLAB and then we've able to use them to create our **afq** structure.

The output from running **AFQ_run** is the **afq** structure containing **ALL** the results. Patient (sub_group = 1) and control (sub_group=0) data are split into a 1X20 structured array of tract diffusion profiles where data for each tract is in a cell of the structure (eg. patient_data(1) is data for the left thalamic radiation). Each diffusion properties is stored as a different field (eg. patient_data(1).FA is a matrix of FA profiles for the left thalamic radiation). Within the data matrix each subject is a row and each location is a column.nIf you want to see the afq structure for later analyses, it must be explicitly saved. In the code below, the **afq** structure is saved under the analyses directory and given a timestamp.

Copy and paste the following into your MATLAB script:

{% highlight matlab %}
% Get home directory:
var = getenv('HOME');

% Add modules to MATLAB. Do not change the order of these programs:
SPM8Path = [var,'/apps/matlab/spm8'];
addpath(genpath(SPM8Path));
vistaPath = [var,'/apps/matlab/vistasoft'];
addpath(genpath(vistaPath));
AFQPath = [var,'/apps/matlab/AFQ'];
addpath(genpath(AFQPath));

load ~/compute/analyses/EDSD/AFQ/sub_dirs.mat
load ~/compute/analyses/EDSD/AFQ/sub_group.mat
outdir = fullfile([var,'/compute/analyses/EDSD/AFQ/']);
outname = fullfile(outdir,['afq_' datestr(now,'yyyy_mm_dd_HHMM')]);
afq = AFQ_Create('sub_dirs', sub_dirs, 'sub_group', sub_group, 'showfigs', false);
[afq, patient_data, control_data, norms, abn, abnTracts] = AFQ_run(sub_dirs, sub_group, afq);
save(outname,'afq');
{% endhighlight %}

### Submit Job Script

Finally, submit the whole process by submitting the job script. AFQ runs serially on the supercomputer and currently there is no way to speed up the process and run it parallel:

{% highlight bash %}
var=`date +"%Y%m%d-%H%M%S"`
mkdir -p ~/logfiles/${var}
sbatch \
-o ~/logfiles/${var}/ouput.txt \
-e ~/logfiles/${var}/error.txt \
~/scripts/EDSD/afq_job.sh
{% endhighlight %}

## Corpus Callosum

In order to segment the corpus callosum, we go through a similar process. Create a job script that will submit a new MATLAB script and then submit the job script to a compute node.

### Job Script

The job script simply submits the MATLAB function **afq_cc_analysis**:

{% highlight bash %}
vi ~/scripts/EDSD/afq_cc_job.sh
{% endhighlight %}

Copy and paste:

{% highlight bash %}
#!/bin/bash

#SBATCH --time=15:00:00   # walltime
#SBATCH --ntasks=1  # number of processor cores (i.e. tasks)
#SBATCH --nodes=1   # number of nodes
#SBATCH --mem-per-cpu=24576M   # memory per CPU core

# Compatibility variables for PBS. Delete if not needed.
export PBS_NODEFILE=`/fslapps/fslutils/generate_pbs_nodefile`
export PBS_JOBID=$SLURM_JOB_ID
export PBS_O_WORKDIR="$SLURM_SUBMIT_DIR"
export PBS_QUEUE=batch

# Set the max number of threads to use for programs using OpenMP. Should be <= ppn. Does nothing if the program doesn't use OpenMP.
export OMP_NUM_THREADS=$SLURM_CPUS_ON_NODE

# LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE
cd ~/scripts/EDSD/
module load matlab/r2013b
matlab -nodisplay -nojvm -nosplash -r afq_cc_analysis
{% endhighlight %}

### MATLAB Script

Create your MATLAB script:

{% highlight bash %}
vi ~/scripts/EDSD/afq_cc_analysis.m
{% endhighlight %}

Copy and paste the following into your script:

{% highlight matlab %}
% Get home directory:
var = getenv('HOME');

% Add modules to MATLAB. Do not change the order of these programs:
SPM8Path = [var,'/apps/matlab/spm8'];
addpath(genpath(SPM8Path));
vistaPath = [var,'/apps/matlab/vistasoft'];
addpath(genpath(vistaPath));
AFQPath = [var,'/apps/matlab/AFQ'];
addpath(genpath(AFQPath));

load ~/compute/analyses/EDSD/AFQ/afq_2016_09_29_0732.mat
outdir = fullfile([var,'/compute/analyses/EDSD/AFQ-CC/']);
outname = fullfile(outdir,['afq_cc_' datestr(now,'yyyy_mm_dd_HHMM')]);
afq = AFQ_SegmentCallosum(afq,0)
save(outname,'afq');
{% endhighlight %}

### Submit Job Script

Finally, submit the whole process by submitting the job script. AFQ corpus callosum segmentation also runs serially on the supercomputer:

{% highlight bash %}
var=`date +"%Y%m%d-%H%M%S"`
mkdir -p ~/logfiles/${var}
sbatch \
-o ~/logfiles/${var}/ouput.txt \
-e ~/logfiles/${var}/error.txt \
~/scripts/EDSD/afq_cc_job.sh
{% endhighlight %}
